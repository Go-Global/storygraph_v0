{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files in Folder:\n",
      "\tinvesting.txt\n",
      "\tmarketwatch.txt\n",
      "\tmarketwatch_parse.txt\n",
      "\tmotleyfool.txt\n",
      "\tmotleyfool_parse.txt\n",
      "\tschaeffers.txt\n",
      "\tschaeffers_parse.txt\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "print(\"Files in Folder:\")\n",
    "print(\"\\t\"+\"\\n\\t\".join(os.listdir(\"../lyft_stock\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read 98 lines from marketwatch file\n"
     ]
    }
   ],
   "source": [
    "# Open a file\n",
    "DOC_NAME = \"marketwatch\"\n",
    "\n",
    "with open(f'../lyft_stock/{DOC_NAME}_parse.txt') as f:\n",
    "    lines = [l.strip() for l in f.readlines() if len(l.strip()) > 0]\n",
    "print(f\"Read {len(lines)} lines from {DOC_NAME} file\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Segment documents by entities and interactions\n",
    "assert \"Entities:\" in lines, \"Error: did not find 'Entities:' header\"\n",
    "assert \"Interactions:\" in lines, \"Error: did not find 'Interactions:' header\"\n",
    "idx = lines.index(\"Interactions:\")\n",
    "entity_lines = lines[1:idx]\n",
    "interaction_lines = lines[idx + 1:]\n",
    "# print(interaction_lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'pandemic,': ['COVID-19 pandemic', 'pandemic'], 'uber,': ['Uber Technologies inc.', 'Uber', 'company', 'companies'], 'lyft,': ['rival Lyft', 'companies', 'Lyft Int.', 'Lyft'], 'consistent lane,': [''], 'earnings preview,': ['fourth quarter results'], 'ride-hailing,': ['ride-hailing industry', 'ride-hailing', 'ride-hailing environment'], 'fourth quarter,': ['fourth quarter'], 'omicron surge,': ['COVID-19 omicron surge'], 'two years': [], 'stability': [], 'Analyst data': [], 'rides': [], 'travel': [], 'US ride-hailing volume': [], 'YipitData analysis': [], 'Raymond James & Associates': ['', 'Raymond James analysts'], \"Uber's fourth quarter bookings\": [], \"Lyft's daily active users\": [], 'driver supply': [], 'New Year': [], 'incentives': ['incentives'], 'status of food delivery': [], \"Uber's Eats division\": ['Eats', 'business'], 'analysts': ['analysts'], 'FactSet': ['FactSet'], 'Estimize': ['Estimize'], 'hedge-fund managers': [], 'executives': [], 'Uber stock': ['Uber shares'], 'Lyft stock': ['Lyft shares'], 'S&P 500': [], 'earnings': ['adjusted earnings', 'earnings'], 'revenue': []}\n"
     ]
    }
   ],
   "source": [
    "# Parse entities\n",
    "def parse_entities(entity_lines):\n",
    "    ent_map = dict()\n",
    "    for line in entity_lines:\n",
    "        if '[' in line:\n",
    "            ent, contents = line.split('[')\n",
    "            contents = [c.strip() for c in contents[:-1].split(',')]\n",
    "        else:\n",
    "            ent, contents = line, []\n",
    "        assert ent.strip() not in ent_map.keys(), f\"Error: entity {ent} already exists in entity map\"\n",
    "        ent_map[ent.strip()] = list(set(contents))\n",
    "    return ent_map\n",
    "entities = parse_entities(entity_lines)\n",
    "print(entities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PARSING HELPERS\n",
    "\n",
    "def split_attributes(chunk):\n",
    "    # If no attributes\n",
    "    if \"(\" not in chunk:\n",
    "        return chunk, None\n",
    "    \n",
    "    # Otherwise get attributes\n",
    "    ent, attrs = chunk.split('(')\n",
    "    ent = ent.strip()\n",
    "    attrs = [attr.strip() for attr in attrs[:-1].split(',')]\n",
    "    return ent.strip(), attrs\n",
    "\n",
    "def split_chunks(ent_string):\n",
    "    # Typically, chunks are split on commas. However, nested actions need to be regarded as a chunk so they must be recombined\n",
    "    # E.g. Stef, {Will, Neil [eat]} -> [\"Stef\", \"{Will, Neil [eat]}\"\"] and not [\"Stef\", \"{Will\", \"Neil [eat]}\"]\n",
    "    \n",
    "    # Split on commas    \n",
    "    ent_list = ent_string.split(',')\n",
    "    \n",
    "    # For {} chunks, recombine them\n",
    "    #TODO check for correct ordering and to handle nesting\n",
    "    open_idxs = []\n",
    "    close_idxs = []\n",
    "    for i, ent in enumerate(ent_list):\n",
    "        if '{' in ent:\n",
    "            open_idxs.append(i)\n",
    "        if '}' in ent:\n",
    "            close_idxs.append(i)\n",
    "\n",
    "    # Make sure # of open and close brackets are equal \n",
    "    assert len(open_idxs) == len(close_idxs), \"Mismatch brackets in line: \" + str(ent_list)\n",
    "    for i, open_idx in enumerate(open_idxs):\n",
    "        # If open and close are in same chunk, no need to merge\n",
    "        if open_idx == close_idxs[i]:\n",
    "            continue\n",
    "        ent_list = ent_list[:open_idx] + [\"\".join(ent_list[open_idx:close_idxs[i] + 1])] + ent_list[close_idxs[i] + 1:]\n",
    "    return [ent.strip() for ent in ent_list]\n",
    "\n",
    "# Parse a line in the Subject-Verb-Object format \"ent1, ent2,... [action] ent3, ent4...\"\"\n",
    "def parse_SVO(nodes, edges, line):\n",
    "    # Get subj ents\n",
    "    # TODO: Handle case: {status of food delivery [changing]} [affects] Uber\n",
    "    subj_ents, rest = [l.strip() for l in line.split('[', maxsplit=1)]\n",
    "    subj_ents = split_chunks(subj_ents) \n",
    "    subj_ents = filter(None, subj_ents) # Drop empty entries\n",
    "    \n",
    "    # Get action and obj_ents\n",
    "    action, obj_ents = rest.split(']', maxsplit=1)\n",
    "    obj_ents = split_chunks(obj_ents)\n",
    "    obj_ents = filter(None, obj_ents) # Drop empty entries\n",
    "    \n",
    "    # Get attributes\n",
    "    action, action_attrs = split_attributes(action)\n",
    "    # Action is always appended first\n",
    "    action_idx = len(nodes)\n",
    "    nodes.append((action, 'interaction'))\n",
    "    \n",
    "    count_idx = len(nodes)\n",
    "    # Add edges\n",
    "    for ent in subj_ents:\n",
    "        if ent[0] == '{':\n",
    "            # Action is always appended first\n",
    "            nodes, edges = parse_SVO(nodes, edges, ent.strip()[1:-1])\n",
    "            \n",
    "            edges.append((count_idx, action_idx))\n",
    "            count_idx = len(nodes)\n",
    "        else:\n",
    "            ent, attrs = split_attributes(ent)\n",
    "            ent_idx = count_idx\n",
    "            nodes.append((ent, 'entity'))\n",
    "            count_idx += 1\n",
    "            # Add any attributes\n",
    "            if attrs:\n",
    "                for attr in attrs:\n",
    "                    nodes.append((attr, 'attribute'))\n",
    "                    count_idx += 1\n",
    "                    edges.append((count_idx, ent_idx))\n",
    "            \n",
    "            # Add entity-action\n",
    "            edges.append((ent_idx, action_idx))\n",
    "    \n",
    "    for ent in obj_ents:\n",
    "        if ent[0] == '{':\n",
    "            # Action is always appended first\n",
    "            nodes, edges = parse_SVO(nodes, edges, ent.strip()[1:-1])\n",
    "            \n",
    "            edges.append((action_idx, count_idx))\n",
    "            count_idx = len(nodes)\n",
    "        else:\n",
    "            ent, attrs = split_attributes(ent)\n",
    "            ent_idx = count_idx\n",
    "            nodes.append((ent, 'entity'))\n",
    "            count_idx += 1\n",
    "            # Add any attributes\n",
    "            if attrs:\n",
    "                for attr in attrs:\n",
    "                    nodes.append((attr, 'attribute'))\n",
    "                    count_idx += 1\n",
    "                    edges.append((count_idx, ent_idx))\n",
    "            # Add entity-action\n",
    "            edges.append((action_idx, ent_idx))\n",
    "            \n",
    "    count = len(nodes)\n",
    "    if action_attrs:\n",
    "        for attr in action_attrs:\n",
    "            nodes.append((attr, 'attribute'))\n",
    "            edges.append((count, action_idx))\n",
    "            count += 1\n",
    "    return nodes, edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parse all interactions\n",
    "def parse_interactions(interaction_lines):\n",
    "    nodes, edges = [], []\n",
    "    for line in interaction_lines[:]:\n",
    "        # line = interaction_lines[0]\n",
    "        # print(\"Processing:\", line)\n",
    "        nodes, edges = parse_SVO(nodes, edges, line)\n",
    "    return nodes, edges\n",
    "\n",
    "nodes, edges = parse_interactions(interaction_lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "Error: key must be a string",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Input \u001b[1;32mIn [32]\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      9\u001b[0m     node_objs\u001b[38;5;241m.\u001b[39mappend(Entity(i, name, PARENT_DOC))\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m type_ \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124minteraction\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m---> 11\u001b[0m     node_objs\u001b[38;5;241m.\u001b[39mappend(\u001b[43mInteraction\u001b[49m\u001b[43m(\u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mPARENT_DOC\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m type_ \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mattribute\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m     13\u001b[0m     node_objs\u001b[38;5;241m.\u001b[39mappend(Attribute(i, name,  PARENT_DOC))\n",
      "File \u001b[1;32mc:\\Users\\Stefa\\Desktop\\Ochre\\storygraph_v0\\models.py:59\u001b[0m, in \u001b[0;36mInteraction.__init__\u001b[1;34m(self, text, parent_doc, attrs, db_id)\u001b[0m\n\u001b[0;32m     58\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, key, text, parent_doc, attrs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mdict\u001b[39m(), db_id\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m---> 59\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(key, text, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minteraction\u001b[39m\u001b[38;5;124m\"\u001b[39m, attrs\u001b[38;5;241m=\u001b[39mattrs, db_id\u001b[38;5;241m=\u001b[39mdb_id)\n\u001b[0;32m     60\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparent_doc \u001b[38;5;241m=\u001b[39m parent_doc\n",
      "File \u001b[1;32mc:\\Users\\Stefa\\Desktop\\Ochre\\storygraph_v0\\models.py:17\u001b[0m, in \u001b[0;36mNode.__init__\u001b[1;34m(self, key, title, node_type, attrs, db_id, raw_count)\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, key, title, node_type, attrs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mdict\u001b[39m(), db_id\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, raw_count\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m):\n\u001b[1;32m---> 17\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(key) \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mstr\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mError: key must be a string\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     18\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkey \u001b[38;5;241m=\u001b[39m key\n\u001b[0;32m     19\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtitle \u001b[38;5;241m=\u001b[39m title\n",
      "\u001b[1;31mAssertionError\u001b[0m: Error: key must be a string"
     ]
    }
   ],
   "source": [
    "from models import *\n",
    "\n",
    "PARENT_DOC = \"lyft-\" + DOC_NAME\n",
    "\n",
    "node_objs = []\n",
    "\n",
    "for i, (name, type_) in enumerate(nodes):\n",
    "    if type_ == 'entity':\n",
    "        node_objs.append(Entity(str(i), name, PARENT_DOC))\n",
    "    elif type_ == 'interaction':\n",
    "        node_objs.append(Interaction(str(i), name, PARENT_DOC))\n",
    "    elif type_ == 'attribute':\n",
    "        node_objs.append(Attribute(str(i), name,  PARENT_DOC))\n",
    "    else:\n",
    "        print(\"Error, unrecognized type:\", type_)\n",
    "\n",
    "assert len(node_objs) == len(nodes), \"Error: mismatched lengths of nodes and nodes objects\"\n",
    "\n",
    "# nodes = dict()\n",
    "# for src, dest in edges:\n",
    "#     for node in [src, dest]:\n",
    "#         key, type_ = node\n",
    "#         if type_ == 'entity':\n",
    "#             if (key, type_) in nodes.keys():\n",
    "#                 nodes[key, type_].raw_count += 1\n",
    "#             else:\n",
    "#                 nodes[key, type_] = Entity(key, PARENT_DOC)\n",
    "#         elif type_ == 'interaction':\n",
    "#             if (key, type_) in nodes.keys():\n",
    "#                 nodes[key, type_].raw_count += 1\n",
    "#             else:\n",
    "#                 nodes[key, type_] = Interaction(key, PARENT_DOC)\n",
    "#         elif type_ == 'attribute':\n",
    "#             if (key, type_) in nodes.keys():\n",
    "#                 nodes[key, type_].raw_count += 1\n",
    "#             else:\n",
    "#                 nodes[key, type_] = Attribute(key, PARENT_DOC)\n",
    "#         else:\n",
    "#             print(\"Error, unrecognized type:\", type_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploading nodes\n",
      "Uploaded looking\n",
      "Uploaded Uber\n",
      "Uploaded Lyft\n",
      "Uploaded lane\n",
      "Uploaded consistent\n",
      "Uploaded two years into the pandemic\n",
      "Uploaded knock\n",
      "Uploaded omicron surge\n",
      "Uploaded bounced back\n",
      "Uploaded Ride-hailing\n",
      "Uploaded thought to have in fourth quarter\n",
      "Uploaded off course\n",
      "Uploaded could\n",
      "Uploaded seeking\n",
      "Ride-hailing already exists in database\n",
      "Uploaded stability\n",
      "Uploaded still\n",
      "Uploaded nearly two years into pandemic\n",
      "Uploaded release\n",
      "Uber already exists in database\n",
      "Lyft already exists in database\n",
      "Uploaded earnings preview\n",
      "Uploaded scheduled\n",
      "Uploaded next week\n",
      "Uploaded show how\n",
      "earnings preview already exists in database\n",
      "Uploaded dealing with\n",
      "Uploaded companies\n",
      "Uploaded ride-hailing environment\n",
      "Uploaded continuously changing\n",
      "Uploaded report\n",
      "Lyft already exists in database\n",
      "Uploaded on Tuesday afternoon\n",
      "Uploaded reports\n",
      "Uber already exists in database\n",
      "Uploaded on Wednesday\n",
      "Uploaded showed\n",
      "Uploaded Analyst data\n",
      "Uploaded recovery\n",
      "Uploaded continue\n",
      "Uploaded in rides & travel\n",
      "Uploaded end of 2021)\n",
      "Uploaded contrasts\n",
      "recovery already exists in database\n",
      "continue already exists in database\n",
      "in rides & travel already exists in database\n",
      "end of 2021) already exists in database\n",
      "Uploaded US ride-hailing volume\n",
      "Uploaded down 40% over the past two years\n",
      "Uploaded alleges\n",
      "Uploaded Analysis\n",
      "Uploaded by Yipit Dat\n",
      "Uploaded based on email receipts)\n",
      "Uploaded down\n",
      "US ride-hailing volume already exists in database\n",
      "Uploaded 40% over the past two years\n",
      "Uploaded estimate\n",
      "Uploaded Raymond James & Associates\n",
      "Uploaded rose\n",
      "Uploaded bookings\n",
      "Uploaded Uber fourth-quarter\n",
      "Uploaded 54%\n",
      "Uploaded grew\n",
      "Uploaded Lyft daily active users\n",
      "Uploaded 41%\n",
      "Uploaded looking for what\n",
      "Uploaded analysts\n",
      "Uploaded say\n",
      "companies already exists in database\n",
      "Uploaded about driver supply\n",
      "Uploaded improved\n",
      "Uploaded driver supply\n",
      "Uploaded in third quarter\n",
      "Uploaded affected\n",
      "omicron surge already exists in database\n",
      "driver supply already exists in database\n",
      "Uploaded in fourth quarter\n",
      "Uploaded into the new year\n",
      "Uploaded offered\n",
      "Uber already exists in database\n",
      "Lyft already exists in database\n",
      "Uploaded incentives\n",
      "Uploaded during pandemic\n",
      "Uploaded reducing or stopping\n",
      "Uber already exists in database\n",
      "Lyft already exists in database\n",
      "incentives already exists in database\n",
      "Uploaded changing\n",
      "Uploaded status of food delivery\n",
      "Uploaded affects\n",
      "Uber already exists in database\n",
      "Uploaded helped\n",
      "Uploaded Eat's division\n",
      "Uber already exists in database\n",
      "Uploaded caused\n",
      "Uploaded lockdowns\n",
      "Uploaded plummeted\n",
      "Uploaded demand for rides\n",
      "Uploaded grown into\n",
      "Eat's division already exists in database\n",
      "Uploaded business\n",
      "Uploaded revenue exceeds rides\n",
      "Uploaded watching\n",
      "analysts already exists in database\n",
      "Uploaded says about how\n",
      "Uber already exists in database\n",
      "Uploaded affect\n",
      "Uploaded delivery growth\n",
      "Uploaded slowing\n",
      "Uploaded bottom line\n",
      "Uploaded Uber's\n",
      "Uploaded slowdown\n",
      "Uploaded growth\n",
      "Uploaded expect\n",
      "Uploaded Truist Securities\n",
      "Uploaded exceed\n",
      "Uploaded Eat's gross bookings\n",
      "Uploaded rides bookings\n",
      "Uploaded in 2022\n",
      "alleges already exists in database\n",
      "Uploaded FactSet\n",
      "expect already exists in database\n",
      "analysts already exists in database\n",
      "Uploaded post\n",
      "Uber already exists in database\n",
      "Uploaded ajusted loss of 30 cents a share\n",
      "Uploaded gathers\n",
      "Uploaded Estimize\n",
      "Uploaded estimates\n",
      "Uploaded from analyst\n",
      "Uploaded hedge-fund managers\n",
      "Uploaded executives\n",
      "Uploaded others)\n",
      "Uploaded expects\n",
      "Estimize already exists in database\n",
      "post already exists in database\n",
      "Uber already exists in database\n",
      "Uploaded loss\n",
      "Uploaded 20 cents a share\n",
      "alleges already exists in database\n",
      "FactSet already exists in database\n",
      "expect already exists in database\n",
      "analysts already exists in database\n",
      "Uploaded revenue\n",
      "Uploaded $5.35 billion\n",
      "Uploaded guiding for\n",
      "Estimize already exists in database\n",
      "revenue already exists in database\n",
      "Uploaded $5.41 billion\n",
      "Uploaded fallen\n",
      "Uploaded Uber stock\n",
      "Uploaded after reporting earnings\n",
      "Uploaded in two of the past four quarters\n",
      "Uploaded five of the 11 reports it has made since going public\n",
      "down already exists in database\n",
      "Uploaded Uber shares\n",
      "Uploaded \n",
      "Uploaded 4.7%\n",
      "Uploaded lost\n",
      "Uploaded S&P 500\n",
      " already exists in database\n",
      "Uploaded 5.2%\n",
      "alleges already exists in database\n",
      "FactSet already exists in database\n",
      "expect already exists in database\n",
      "analysts already exists in database\n",
      "post already exists in database\n",
      "Lyft already exists in database\n",
      "Uploaded adjusted earnings\n",
      "Uploaded 8 cents a share\n",
      "Uploaded on average\n",
      "expects already exists in database\n",
      "Estimize already exists in database\n",
      "Uploaded earnings\n",
      "8 cents a share already exists in database\n",
      "alleges already exists in database\n",
      "FactSet already exists in database\n",
      "expect already exists in database\n",
      "analysts already exists in database\n",
      "revenue already exists in database\n",
      "Uploaded $940.1 million\n",
      "on average already exists in database\n",
      "Uploaded is\n",
      "Uploaded Estimize guidance\n",
      "Uploaded 944.4 million\n",
      "fallen already exists in database\n",
      "Uploaded Lyft stock\n",
      " already exists in database\n",
      "Uploaded after reporting earnings in two of the past four quarter\n",
      "Uploaded and 6 of the 11 reports it has made since going public)\n",
      "fallen already exists in database\n",
      "Uploaded Lyft shares\n",
      "Uploaded 4%\n",
      "Uploaded this year through Friday\n",
      "Uploaded bullish\n",
      "analysts already exists in database\n",
      "Uploaded ride-hailing\n",
      "Uploaded optimistic\n",
      "analysts already exists in database\n",
      "Uber already exists in database\n",
      "optimistic already exists in database\n",
      "analysts already exists in database\n",
      "Lyft already exists in database\n",
      "Uploaded slightly less so\n",
      "expect already exists in database\n",
      "Uploaded Truist\n",
      "Uploaded show\n",
      "Uber already exists in database\n",
      "Uploaded Ebitda\n",
      "Uploaded sustained positive adjusted in 4Q21\n",
      "Uploaded achieving\n",
      "Uber already exists in database\n",
      "Uploaded Ebitda profitability\n",
      "Uploaded in the fourth quarter\n",
      "expect already exists in database\n",
      "Truist already exists in database\n",
      "Uploaded maintain\n",
      "Lyft already exists in database\n",
      "Ebitda already exists in database\n",
      "Uploaded positive\n",
      "Uploaded in the second and third quarters of 2021\n",
      "expect already exists in database\n",
      "Uploaded Raymond James analysts\n",
      "bookings already exists in database\n",
      "Uploaded solid overal\n",
      "Uploaded for Uber)\n",
      "Uploaded causes\n",
      "Uploaded acquisitions over the last year\n",
      "Uploaded solid overall bookings for Uber\n",
      "expect already exists in database\n",
      "Raymond James analysts already exists in database\n",
      "growth already exists in database\n",
      "Uploaded mid-to-high-teen\n",
      "Uploaded for Lyft)\n",
      "Uploaded saw\n",
      "Raymond James analysts already exists in database\n",
      "Uploaded sequential growth\n",
      "Uploaded slowe\n",
      "Uploaded sequential\n",
      "Uploaded in bookings\n",
      "Uploaded for Lyft\n",
      "Uploaded in the fourth quarter)\n",
      "Uploaded rate\n",
      "Uploaded Mizuho Securities analysts\n",
      "Uber already exists in database\n",
      "Uploaded a top opening play\n",
      "expect already exists in database\n",
      "Mizuho Securities analysts already exists in database\n",
      "Uploaded improve\n",
      "driver supply already exists in database\n",
      "Uploaded hold its own against\n",
      "Uploaded Uber Eats\n",
      "Uploaded DoorDash\n",
      "Uploaded anticipate\n",
      "Mizuho Securities analysts already exists in database\n",
      "Uploaded gig labor issues\n",
      "Uploaded positive regulatory resolution at state level\n",
      "Uploaded track similar to\n",
      "Uploaded New York\n",
      "Uploaded Massachusetts\n",
      "Uploaded Prop 22\n",
      "Uploaded in California\n",
      "Uploaded likely\n",
      "Uploaded surveyed\n",
      "FactSet already exists in database\n",
      "analysts already exists in database\n",
      "Uploaded 38\n",
      "rate already exists in database\n",
      "Uploaded FactSet Analysts\n",
      "Uploaded 32\n",
      "Uploaded Uber Stock\n",
      "Uploaded buy\n",
      "rate already exists in database\n",
      "FactSet Analysts already exists in database\n",
      "Uploaded 4\n",
      "Uber Stock already exists in database\n",
      "Uploaded hold\n",
      "rate already exists in database\n",
      "FactSet Analysts already exists in database\n",
      "Uploaded 2\n",
      "Uber Stock already exists in database\n",
      "Uploaded overweight\n",
      "Uploaded set\n",
      "FactSet Analysts already exists in database\n",
      "Uploaded Price target\n",
      "Uploaded averag\n",
      "Uploaded $67.36)\n",
      "surveyed already exists in database\n",
      "FactSet already exists in database\n",
      "analysts already exists in database\n",
      "Uploaded 34\n",
      "rate already exists in database\n",
      "FactSet Analysts already exists in database\n",
      "Uploaded 19\n",
      "Uploaded Lyft Stock\n",
      "buy already exists in database\n",
      "rate already exists in database\n",
      "FactSet Analysts already exists in database\n",
      "Uploaded 11\n",
      "Lyft Stock already exists in database\n",
      "hold already exists in database\n",
      "rate already exists in database\n",
      "FactSet Analysts already exists in database\n",
      "Uploaded 3\n",
      "Lyft Stock already exists in database\n",
      "Uploaded sell\n",
      "rate already exists in database\n",
      "FactSet Analysts already exists in database\n",
      "Uploaded 1\n",
      "Lyft Stock already exists in database\n",
      "overweight already exists in database\n",
      "set already exists in database\n",
      "Uploaded Analysts\n",
      "Uploaded price target\n",
      "averag already exists in database\n",
      "Uploaded $64.79)\n",
      "Uploaded 206 nodes out of 316 total\n",
      "Adding Edges\n",
      "Uploaded ('relation', 'Uber', 'looking')\n",
      "Uploaded ('relation', 'Lyft', 'looking')\n",
      "Uploaded ('relation', 'two years into the pandemic', 'lane')\n",
      "Uploaded ('relation', 'looking', 'lane')\n",
      "Uploaded ('relation', 'two years into the pandemic', 'looking')\n",
      "Uploaded ('relation', 'omicron surge', 'knock')\n",
      "Uploaded ('relation', 'Ride-hailing', 'bounced back')\n",
      "Uploaded ('relation', 'thought to have in fourth quarter', 'bounced back')\n",
      "Uploaded ('relation', 'knock', 'bounced back')\n",
      "Uploaded ('relation', 'off course', 'knock')\n",
      "Uploaded ('relation', 'could', 'knock')\n",
      "Uploaded ('relation', 'Ride-hailing', 'seeking')\n",
      "Uploaded ('relation', 'seeking', 'stability')\n",
      "Uploaded ('relation', 'still', 'seeking')\n",
      "Uploaded ('relation', 'nearly two years into pandemic', 'seeking')\n",
      "Uploaded ('relation', 'Uber', 'release')\n",
      "Uploaded ('relation', 'Lyft', 'release')\n",
      "Uploaded ('relation', 'release', 'earnings preview')\n",
      "Uploaded ('relation', 'scheduled', 'release')\n",
      "Uploaded ('relation', 'next week', 'release')\n",
      "Uploaded ('relation', 'earnings preview', 'show how')\n",
      "Uploaded ('relation', 'companies', 'dealing with')\n",
      "Uploaded ('relation', 'report', 'ride-hailing environment')\n",
      "Uploaded ('relation', 'dealing with', 'ride-hailing environment')\n",
      "Uploaded ('relation', 'show how', 'dealing with')\n",
      "Uploaded ('relation', 'Lyft', 'report')\n",
      "Uploaded ('relation', 'on Tuesday afternoon', 'report')\n",
      "Uploaded ('relation', 'Uber', 'reports')\n",
      "Uploaded ('relation', 'on Wednesday', 'reports')\n",
      "Uploaded ('relation', 'Analyst data', 'showed')\n",
      "Uploaded ('relation', 'in rides & travel', 'recovery')\n",
      "Uploaded ('relation', 'showed', 'recovery')\n",
      "Uploaded ('relation', 'showed', 'in rides & travel')\n",
      "Uploaded ('relation', 'showed', 'end of 2021)')\n",
      "('relation', 'in rides & travel', 'recovery') already exists in database\n",
      "Uploaded ('relation', 'recovery', 'contrasts')\n",
      "Uploaded ('relation', 'in rides & travel', 'contrasts')\n",
      "Uploaded ('relation', 'end of 2021)', 'contrasts')\n",
      "Uploaded ('relation', 'alleges', 'US ride-hailing volume')\n",
      "Uploaded ('relation', 'contrasts', 'US ride-hailing volume')\n",
      "Uploaded ('relation', 'based on email receipts)', 'Analysis')\n",
      "Uploaded ('relation', 'Analysis', 'alleges')\n",
      "Uploaded ('relation', 'based on email receipts)', 'alleges')\n",
      "Uploaded ('relation', 'US ride-hailing volume', 'down')\n",
      "Uploaded ('relation', '40% over the past two years', 'down')\n",
      "Uploaded ('relation', 'alleges', 'down')\n",
      "Uploaded ('relation', 'Raymond James & Associates', 'estimate')\n",
      "Uploaded ('relation', '54%', 'bookings')\n",
      "Uploaded ('relation', 'bookings', 'rose')\n",
      "Uploaded ('relation', '54%', 'rose')\n",
      "Uploaded ('relation', 'estimate', 'rose')\n",
      "Uploaded ('relation', 'Lyft daily active users', 'grew')\n",
      "Uploaded ('relation', 'grew', '41%')\n",
      "Uploaded ('relation', 'analysts', 'looking for what')\n",
      "Uploaded ('relation', 'companies', 'say')\n",
      "Uploaded ('relation', 'say', 'about driver supply')\n",
      "Uploaded ('relation', 'looking for what', 'say')\n",
      "Uploaded ('relation', 'driver supply', 'improved')\n",
      "Uploaded ('relation', 'in third quarter', 'improved')\n",
      "Uploaded ('relation', 'omicron surge', 'affected')\n",
      "Uploaded ('relation', 'affected', 'driver supply')\n",
      "Uploaded ('relation', 'in fourth quarter', 'affected')\n",
      "Uploaded ('relation', 'into the new year', 'affected')\n",
      "Uploaded ('relation', 'Uber', 'offered')\n",
      "Uploaded ('relation', 'Lyft', 'offered')\n",
      "Uploaded ('relation', 'offered', 'incentives')\n",
      "Uploaded ('relation', 'during pandemic', 'offered')\n",
      "Uploaded ('relation', 'Uber', 'reducing or stopping')\n",
      "Uploaded ('relation', 'Lyft', 'reducing or stopping')\n",
      "Uploaded ('relation', 'reducing or stopping', 'incentives')\n",
      "Uploaded ('relation', 'status of food delivery', 'changing')\n",
      "Uploaded ('relation', 'affects', 'Uber')\n",
      "Uploaded ('relation', 'changing', 'affects')\n",
      "Uploaded ('relation', \"Eat's division\", 'helped')\n",
      "Uploaded ('relation', 'helped', 'Uber')\n",
      "Uploaded ('relation', 'lockdowns', 'caused')\n",
      "Uploaded ('relation', 'demand for rides', 'plummeted')\n",
      "Uploaded ('relation', 'caused', 'plummeted')\n",
      "Uploaded ('relation', \"Eat's division\", 'grown into')\n",
      "Uploaded ('relation', 'watching', 'business')\n",
      "Uploaded ('relation', 'grown into', 'business')\n",
      "Uploaded ('relation', 'analysts', 'watching')\n",
      "Uploaded ('relation', 'Uber', 'says about how')\n",
      "Uploaded ('relation', 'bottom line', 'delivery growth')\n",
      "Uploaded ('relation', 'delivery growth', 'affect')\n",
      "Uploaded ('relation', 'slowdown', 'bottom line')\n",
      "Uploaded ('relation', 'affect', 'bottom line')\n",
      "Uploaded ('relation', 'says about how', 'affect')\n",
      "Uploaded ('relation', 'watching', 'says about how')\n",
      "Uploaded ('relation', 'slowdown', 'growth')\n",
      "Uploaded ('relation', 'Truist Securities', 'expect')\n",
      "Uploaded ('relation', \"Eat's gross bookings\", 'exceed')\n",
      "Uploaded ('relation', 'exceed', 'rides bookings')\n",
      "Uploaded ('relation', 'in 2022', 'exceed')\n",
      "Uploaded ('relation', 'expect', 'exceed')\n",
      "Uploaded ('relation', 'FactSet', 'alleges')\n",
      "Uploaded ('relation', 'analysts', 'expect')\n",
      "Uploaded ('relation', 'Uber', 'post')\n",
      "Uploaded ('relation', 'post', 'ajusted loss of 30 cents a share')\n",
      "Uploaded ('relation', 'expect', 'post')\n",
      "Uploaded ('relation', 'alleges', 'expect')\n",
      "Uploaded ('relation', 'Estimize', 'gathers')\n",
      "Uploaded ('relation', 'hedge-fund managers', 'estimates')\n",
      "Uploaded ('relation', 'gathers', 'estimates')\n",
      "Uploaded ('relation', 'gathers', 'hedge-fund managers')\n",
      "Uploaded ('relation', 'gathers', 'executives')\n",
      "Uploaded ('relation', 'gathers', 'others)')\n",
      "Uploaded ('relation', 'Estimize', 'expects')\n",
      "('relation', 'Uber', 'post') already exists in database\n",
      "Uploaded ('relation', 'alleges', 'loss')\n",
      "Uploaded ('relation', 'post', 'loss')\n",
      "Uploaded ('relation', 'expects', 'post')\n",
      "('relation', 'FactSet', 'alleges') already exists in database\n",
      "('relation', 'analysts', 'expect') already exists in database\n",
      "Uploaded ('relation', 'guiding for', 'revenue')\n",
      "Uploaded ('relation', 'expect', 'revenue')\n",
      "('relation', 'alleges', 'expect') already exists in database\n",
      "Uploaded ('relation', 'Estimize', 'guiding for')\n",
      "Uploaded ('relation', 'fallen', 'revenue')\n",
      "('relation', 'guiding for', 'revenue') already exists in database\n",
      "Uploaded ('relation', 'Uber stock', 'fallen')\n",
      "Uploaded ('relation', 'after reporting earnings', 'fallen')\n",
      "Uploaded ('relation', 'in two of the past four quarters', 'fallen')\n",
      "Uploaded ('relation', 'five of the 11 reports it has made since going public', 'fallen')\n",
      "Uploaded ('relation', 'Uber shares', 'down')\n",
      "Uploaded ('relation', 'lost', '')\n",
      "Uploaded ('relation', 'down', '')\n",
      "Uploaded ('relation', 'S&P 500', 'lost')\n",
      "Uploaded ('relation', 'alleges', '')\n",
      "('relation', 'lost', '') already exists in database\n",
      "('relation', 'FactSet', 'alleges') already exists in database\n",
      "('relation', 'analysts', 'expect') already exists in database\n",
      "Uploaded ('relation', 'Lyft', 'post')\n",
      "Uploaded ('relation', 'on average', 'adjusted earnings')\n",
      "Uploaded ('relation', 'post', 'adjusted earnings')\n",
      "('relation', 'expect', 'post') already exists in database\n",
      "Uploaded ('relation', 'on average', 'expect')\n",
      "('relation', 'alleges', 'expect') already exists in database\n",
      "('relation', 'Estimize', 'expects') already exists in database\n",
      "Uploaded ('relation', 'alleges', 'earnings')\n",
      "Uploaded ('relation', 'expects', 'earnings')\n",
      "('relation', 'FactSet', 'alleges') already exists in database\n",
      "('relation', 'analysts', 'expect') already exists in database\n",
      "Uploaded ('relation', 'on average', 'revenue')\n",
      "('relation', 'expect', 'revenue') already exists in database\n",
      "('relation', 'on average', 'expect') already exists in database\n",
      "('relation', 'alleges', 'expect') already exists in database\n",
      "Uploaded ('relation', 'Estimize guidance', 'is')\n",
      "Uploaded ('relation', 'is', '944.4 million')\n",
      "Uploaded ('relation', 'Lyft stock', 'fallen')\n",
      "Uploaded ('relation', 'and 6 of the 11 reports it has made since going public)', '')\n",
      "Uploaded ('relation', 'fallen', '')\n",
      "Uploaded ('relation', 'fallen', 'and 6 of the 11 reports it has made since going public)')\n",
      "Uploaded ('relation', 'Lyft shares', 'fallen')\n",
      "Uploaded ('relation', '4%', 'fallen')\n",
      "Uploaded ('relation', 'this year through Friday', 'fallen')\n",
      "Uploaded ('relation', 'analysts', 'bullish')\n",
      "Uploaded ('relation', 'bullish', 'ride-hailing')\n",
      "Uploaded ('relation', 'analysts', 'optimistic')\n",
      "Uploaded ('relation', 'optimistic', 'Uber')\n",
      "('relation', 'analysts', 'optimistic') already exists in database\n",
      "Uploaded ('relation', 'optimistic', 'Lyft')\n",
      "Uploaded ('relation', 'slightly less so', 'optimistic')\n",
      "Uploaded ('relation', 'Truist', 'expect')\n",
      "Uploaded ('relation', 'Uber', 'show')\n",
      "Uploaded ('relation', 'achieving', 'Ebitda')\n",
      "Uploaded ('relation', 'show', 'Ebitda')\n",
      "Uploaded ('relation', 'expect', 'show')\n",
      "Uploaded ('relation', 'Uber', 'achieving')\n",
      "Uploaded ('relation', 'achieving', 'Ebitda profitability')\n",
      "Uploaded ('relation', 'in the fourth quarter', 'achieving')\n",
      "('relation', 'Truist', 'expect') already exists in database\n",
      "Uploaded ('relation', 'Lyft', 'maintain')\n",
      "Uploaded ('relation', 'in the second and third quarters of 2021', 'Ebitda')\n",
      "Uploaded ('relation', 'maintain', 'Ebitda')\n",
      "Uploaded ('relation', 'in the second and third quarters of 2021', 'maintain')\n",
      "Uploaded ('relation', 'expect', 'maintain')\n",
      "Uploaded ('relation', 'Raymond James analysts', 'expect')\n",
      "Uploaded ('relation', 'for Uber)', 'bookings')\n",
      "Uploaded ('relation', 'expect', 'bookings')\n",
      "Uploaded ('relation', 'expect', 'for Uber)')\n",
      "Uploaded ('relation', 'acquisitions over the last year', 'causes')\n",
      "Uploaded ('relation', 'causes', 'solid overall bookings for Uber')\n",
      "('relation', 'Raymond James analysts', 'expect') already exists in database\n",
      "Uploaded ('relation', 'for Lyft)', 'growth')\n",
      "Uploaded ('relation', 'expect', 'growth')\n",
      "Uploaded ('relation', 'expect', 'for Lyft)')\n",
      "Uploaded ('relation', 'Raymond James analysts', 'saw')\n",
      "Uploaded ('relation', 'sequential', 'sequential growth')\n",
      "Uploaded ('relation', 'saw', 'sequential growth')\n",
      "Uploaded ('relation', 'saw', 'sequential')\n",
      "Uploaded ('relation', 'saw', 'in bookings')\n",
      "Uploaded ('relation', 'saw', 'for Lyft')\n",
      "Uploaded ('relation', 'saw', 'in the fourth quarter)')\n",
      "Uploaded ('relation', 'Mizuho Securities analysts', 'rate')\n",
      "Uploaded ('relation', 'rate', 'Uber')\n",
      "Uploaded ('relation', 'a top opening play', 'rate')\n",
      "Uploaded ('relation', 'Mizuho Securities analysts', 'expect')\n",
      "Uploaded ('relation', 'driver supply', 'improve')\n",
      "Uploaded ('relation', 'expect', 'improve')\n",
      "Uploaded ('relation', 'Uber Eats', 'hold its own against')\n",
      "Uploaded ('relation', 'hold its own against', 'DoorDash')\n",
      "Uploaded ('relation', 'expect', 'hold its own against')\n",
      "Uploaded ('relation', 'Mizuho Securities analysts', 'anticipate')\n",
      "Uploaded ('relation', 'track similar to', 'gig labor issues')\n",
      "Uploaded ('relation', 'anticipate', 'gig labor issues')\n",
      "Uploaded ('relation', 'New York', 'track similar to')\n",
      "Uploaded ('relation', 'Massachusetts', 'track similar to')\n",
      "Uploaded ('relation', 'likely', 'Prop 22')\n",
      "Uploaded ('relation', 'track similar to', 'Prop 22')\n",
      "Uploaded ('relation', 'likely', 'track similar to')\n",
      "Uploaded ('relation', 'FactSet', 'surveyed')\n",
      "Uploaded ('relation', 'rate', 'analysts')\n",
      "Uploaded ('relation', 'surveyed', 'analysts')\n",
      "Uploaded ('relation', 'Uber Stock', 'FactSet Analysts')\n",
      "Uploaded ('relation', 'FactSet Analysts', 'rate')\n",
      "Uploaded ('relation', 'rate', 'Uber Stock')\n",
      "Uploaded ('relation', 'buy', 'rate')\n",
      "('relation', 'Uber Stock', 'FactSet Analysts') already exists in database\n",
      "('relation', 'FactSet Analysts', 'rate') already exists in database\n",
      "('relation', 'rate', 'Uber Stock') already exists in database\n",
      "Uploaded ('relation', 'hold', 'rate')\n",
      "('relation', 'Uber Stock', 'FactSet Analysts') already exists in database\n",
      "('relation', 'FactSet Analysts', 'rate') already exists in database\n",
      "('relation', 'rate', 'Uber Stock') already exists in database\n",
      "Uploaded ('relation', 'overweight', 'rate')\n",
      "Uploaded ('relation', 'FactSet Analysts', 'set')\n",
      "Uploaded ('relation', '$67.36)', 'Price target')\n",
      "Uploaded ('relation', 'set', 'Price target')\n",
      "Uploaded ('relation', 'set', '$67.36)')\n",
      "('relation', 'FactSet', 'surveyed') already exists in database\n",
      "('relation', 'rate', 'analysts') already exists in database\n",
      "('relation', 'surveyed', 'analysts') already exists in database\n",
      "Uploaded ('relation', 'Lyft Stock', 'FactSet Analysts')\n",
      "('relation', 'FactSet Analysts', 'rate') already exists in database\n",
      "Uploaded ('relation', 'rate', 'Lyft Stock')\n",
      "('relation', 'buy', 'rate') already exists in database\n",
      "('relation', 'Lyft Stock', 'FactSet Analysts') already exists in database\n",
      "('relation', 'FactSet Analysts', 'rate') already exists in database\n",
      "('relation', 'rate', 'Lyft Stock') already exists in database\n",
      "('relation', 'hold', 'rate') already exists in database\n",
      "('relation', 'Lyft Stock', 'FactSet Analysts') already exists in database\n",
      "('relation', 'FactSet Analysts', 'rate') already exists in database\n",
      "('relation', 'rate', 'Lyft Stock') already exists in database\n",
      "Uploaded ('relation', 'sell', 'rate')\n",
      "('relation', 'Lyft Stock', 'FactSet Analysts') already exists in database\n",
      "('relation', 'FactSet Analysts', 'rate') already exists in database\n",
      "('relation', 'rate', 'Lyft Stock') already exists in database\n",
      "('relation', 'overweight', 'rate') already exists in database\n",
      "Uploaded ('relation', 'Analysts', 'set')\n",
      "Uploaded ('relation', '$64.79)', 'price target')\n",
      "Uploaded ('relation', 'set', 'price target')\n",
      "Uploaded ('relation', 'set', '$64.79)')\n",
      "Uploaded 211 edges out of 253 total\n",
      "Finished\n"
     ]
    }
   ],
   "source": [
    "# Upload to DB\n",
    "from graph_driver import GraphDBDriver\n",
    "from models import *\n",
    "\n",
    "driver = GraphDBDriver(remote=False)\n",
    "print(\"Uploading nodes\")\n",
    "driver.upload_nodes(node_objs)\n",
    "# driver.upload_nodes([node for node in nodes.values()])\n",
    "\n",
    "print(\"Adding Edges\")\n",
    "edge_objs = []\n",
    "for source, dest in edges:\n",
    "    edge_objs.append(Edge(\"relation\", node_objs[source], node_objs[dest]))\n",
    "driver.upload_edges(edge_objs)\n",
    "# print(\"Cleaning up\")\n",
    "# driver.raw_query(\"MATCH (n:entity) WHERE n.key=\\\"entity1\\\" DETACH DELETE n\")\n",
    "# driver.raw_query(\"MATCH (n:interaction) WHERE n.key=\\\"interacted\\\" DETACH DELETE n\")\n",
    "# print(\"Deleted nodes\")\n",
    "driver.close()\n",
    "print(\"Finished\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "109"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(nodes.values())"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "2673dc15ede12b932d4705493734f5e380ada2f0f3d41e925a93ee6556f8662d"
  },
  "kernelspec": {
   "display_name": "Python 3.9.9 64-bit ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
